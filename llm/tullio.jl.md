================
CODE SNIPPETS
================
TITLE: Tullio.jl Forward Pass Setup (make)
DESCRIPTION: Illustrates the setup function (`make`) generated by Tullio.jl for preparing the computation. It determines array axes, return types, and initializes the output array before calling the core `act!` function via `threader`.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_35

LANGUAGE: julia
CODE:
```
function make(A, B)
    ax_i = axes(A,1)
    ax_j = axes(B,2)
    ax_k = axes(A,2) # and check this is == axes(B,1)
    rhs(A,B,i,j,k) = tanh(A[i,k] * B[k,j])
    T = Core.Compiler.return_type(rhs, eltype.((A,B,1,1,1))) # plus a fallback
    C = similar(A, T, (ax_i, ax_j))
    Tullio.threader(act!, Array{T}, C, (A,B), (ax_i,ax_j), (ax_k,), +, 64^3)
    return C
end

C = Tullio.Eval(make, ∇make)(A, B)
```

--------------------------------

TITLE: Tullio.jl Backward Pass Setup (∇make)
DESCRIPTION: Illustrates the setup function (`∇make`) for the backward pass in Tullio.jl. It initializes gradient arrays and uses `∇threader` to distribute the gradient computation across threads.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_38

LANGUAGE: julia
CODE:
```
function ∇make(ΔC, C, A, B)
    ΔA = similar(A) .= 0
    ΔB = similar(B) .= 0
    ax_i, ax_k = axes(A); ax_j = axes(B,2)
    Tullio.∇threader(∇act!, Array{T}, (ax_k,), (ax_i, ax_j), nothing)
    return (ΔA, ΔB)
end
```

--------------------------------

TITLE: Tullio: Matrix Multiplication Example
DESCRIPTION: Shows how to implement matrix multiplication using the @tullio macro, effectively summing over the common column index.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_7

LANGUAGE: julia
CODE:
```
using Tullio

mult(M,Q) = @tullio P[x,y] := M[x,c] * Q[y,c]  # sum over c ∈ 1:7

# Example usage:
M = rand(3, 7)
Q = rand(5, 7)
# Note: For standard matrix multiplication, Q should be transposed or have compatible dimensions.
# The example implies Q[y,c] is used, which might be a typo in the source and intended as Q[c,y] or transpose(Q)[y,c].
# Assuming the intent is M * transpose(Q):
# mult(M,Q) ≈ M * transpose(Q)

```

--------------------------------

TITLE: Tullio: Create Array with Summation
DESCRIPTION: Demonstrates creating a new array `M` by summing `N` and `K` over indices `i,j`. This example shows basic summation and assignment to a new array.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_0

LANGUAGE: julia
CODE:
```
@tullio M[x,y,c] := N[x+i, y+j,c] * K[i,j]
```

--------------------------------

TITLE: Einsum Notation for Matrix Multiplication
DESCRIPTION: Demonstrates equivalent matrix multiplication operations using einsum notation across different Julia libraries: TensorOperations.jl, OMEinsum.jl, TensorCast.jl, and Einsum.jl. These examples showcase the common syntax for expressing tensor contractions.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_31

LANGUAGE: julia
CODE:
```
@tensor C[i,j] := A[i,k] * B[k,j]         # TensorOperations.jl
@ein C[i,j] := A[i,k] * B[k,j]            # OMEinsum.jl
@matmul C[i,j] := sum(k) A[i,k] * B[k,j]  # TensorCast.jl
@einsum C[i,j] := A[i,k] * B[k,j]         # Einsum.jl
```

--------------------------------

TITLE: Tullio.jl Scalar Reduction Example
DESCRIPTION: Illustrates a scalar reduction operation using Tullio.jl, where the result is a single scalar value. It shows how the `act!` function's behavior changes for scalar reductions, returning the accumulated sum directly.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_41

LANGUAGE: julia
CODE:
```
@tullio s := A[i,j] * log(B[j,i])
```

--------------------------------

TITLE: Tullio.jl Forward Pass Expansion (act!)
DESCRIPTION: Presents the expanded Julia function generated by Tullio.jl for the matrix multiplication with tanh example. This function (`act!`) handles the core computation, including accumulation and applying the finalizer.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_34

LANGUAGE: julia
CODE:
```
function act!(::Type, C::AbstractArray{T}, A, B, ax_i, ax_j, ax_k, keep=nothing, final=true) where T
    @inbounds @fastmath for i in ax_i
        for j in ax_j
            acc = isnothing(keep) ? zero(T) : C[i,j]
            for k in ax_k
                acc += A[i,k] * B[k,j]
            end
            C[i,j] = isnothing(final) ? acc : tanh(acc)
        end
    end
end
```

--------------------------------

TITLE: Tullio: Product Reduction with Indirect Indexing
DESCRIPTION: Illustrates performing a product reduction (`*`) over index `k` using indirect indexing (`ind[k]`). This showcases handling of products and complex indexing.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_3

LANGUAGE: julia
CODE:
```
@tullio (*) Z[j] := X[ind[k],j] * exp(-Y[k])
```

--------------------------------

TITLE: Tullio: Indexing with Ranges and Shifts
DESCRIPTION: Illustrates how Tullio handles indexing with ranges, including calculating ranges based on dependencies and automatic index shifting.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_11

LANGUAGE: julia
CODE:
```
using Tullio, Test

A = [abs2(i - 11) for i in 1:21]

# Downsample -- range of i is that allowed by both terms
@tullio B[i] := (A[2i] + A[2i+1])/2  # 1:10 == intersect(1:10, 0:10)

# Shifts -- range of i calculated in terms of that given for j
@tullio M[i,j] := A[i+j-1]  (j in 1:15)  # i in 1:7
@tullio M[i+_,j] := A[i+j]  (j in 1:15)  # i in 0:6, automatic shift "i+_"
```

--------------------------------

TITLE: Tullio: Basic Summation and Broadcasting
DESCRIPTION: Demonstrates fundamental Tullio usage, including adding the package, importing, performing a simple summation over an index, and broadcasting operations without summation.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_6

LANGUAGE: julia
CODE:
```
using Pkg; Pkg.add("Tullio")
using Tullio, Test
M = rand(1:20, 3, 7)

# Sum over r ∈ 1:3, for each c ∈ 1:7
@tullio S[1,c] := M[r,c]
@test S == sum(M, dims=1)

# Loop over ρ & c, no sum -- broadcasting
@tullio Q[ρ,c] := M[ρ,c] + sqrt(S[1,c])
@test Q ≈ M .+ sqrt.(S)
```

--------------------------------

TITLE: Tullio Macro Keyword Options and Syntax
DESCRIPTION: Comprehensive documentation for @tullio macro keyword arguments, including threading, SIMD (AVX), gradient calculation, tensor operations, and assignment syntax.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_30

LANGUAGE: APIDOC
CODE:
```
Tullio Macro Options:

Default settings: @tullio threads=true fastmath=true avx=true tensor=true cuda=256 grad=Base verbose=false A[i,j] := ...

Keyword Options:
- `threads`: Controls threading. `threads=false` disables, `threads=N` sets a threshold size for work division.
- `fastmath`: Enables fast math optimizations.
- `avx`: Controls LoopVectorization. `avx=false` disables, `avx=N` inserts `@avx unroll=N`.
- `grad`: Controls gradient calculation. `grad=false` disables, `grad=Dual` uses ForwardDiff.
- `nograd`: Specifies arrays for which gradients should not be calculated (e.g., `nograd=A`, `nograd=(A,B,C)`).
- `tensor`: Controls TensorOperations usage. `tensor=false` disables.
- `cuda`: Configures GPU kernels, e.g., `cuda=256` passes to `kernel(CUDA(), 256)`.
- `verbose`: Controls output verbosity. `verbose=true` prints inferred ranges, `verbose=2` prints everything.
- `init`: Sets initial value for reductions (e.g., `init=0.0`).

Assignment Syntax:
- `A[i,j] := ...`: Creates a new array.
- `A[i,j] = ...`: Writes into an existing array.
- `A[i,j] += ...`: In-place update.
- `A[row=i, col=j] := ...`: Creates a `NamedDimsArray`.
- `@tullio (*) A[i,j] := ...` or `@tullio A[i,j] *= ...`: Product reduction.
- `@tullio (f) A[i,j] ^= ...`: In-place update for reduction `f`.

Implicit Behavior:
- Indices without shifts must have the same range.
- Shifted indices run over the intersection of possible ranges.
- Shifted output indices start at 1 unless `OffsetArrays` is visible.
- `@avx` and gradient calculations are switched off by complex syntax (e.g., arrays of arrays).
- Gradient hooks are attached for `ReverseDiff`, `Tracker`, `Zygote` (packages need not be loaded).
- Gradients are defined for `(+)` (default), `min`, `max` reductions.
- GPU kernels require `KernelAbstractions` and `CUDA`.
- CPU kernels from `KernelAbstractions` are called when `threads=false`.

Extras:
- `A[i] := i^2 (i in 1:10)`: Explicitly specify index ranges.
- `A[i] := B[i, $col] - C[i, 2]`: Fix an index to a constant.
- `A[i] := $d * B[i]`: Include other constants (no gradient for `d`).
- `A[mod(i), clamp(j)]`: Map indices to axes and disable range inference.
- `A[pad(i,3)]`: Extend range, inserting zeros (or `pad=NaN` value) outside `A`.
- `A[i+_] :=`: Inserts shift to make `A` one-based.
- `Tullio.@printgrad`: Prints symbolic derivative calculations.

Macros:
- `Tullio.@tensor`: Uses TensorOperations with gradient definitions.
- `Tullio.@einsum`: Variant for running Einsum.jl tests.
```

--------------------------------

TITLE: Tullio: FFT and Index Functions
DESCRIPTION: Illustrates using @tullio for Fourier transforms and applying functions to indices within the macro.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_14

LANGUAGE: julia
CODE:
```
using Tullio, FFTW

S = [0,1,0,0, 0,0,0,0]
fft(S) ≈ @tullio F[k] := S[x] * exp(-im*pi/8 * (k-1) * x)  (k ∈ axes(S,1))
```

--------------------------------

TITLE: Tullio: Stencil Operation with Clamping
DESCRIPTION: Illustrates creating a stencil operation using @tullio, employing `clamp` for boundary handling and accessing offsets.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_28

LANGUAGE: Julia
CODE:
```
# A stencil?
offsets = [(a,b) for a in -2:2 for b in -2:2 if a>=b] # vector of tuples

@tullio out[x,y,1] = begin
        a,b = offsets[k]
        i = clamp(x+a, extrema(axes(mat,1))...)
        # j = clamp(y+b, extrema(axes(mat,2))...)
        @inbounds mat[i, clamp(y+b), 1] * 10
    end # ranges of x,y read from out[x,y,1]
```

--------------------------------

TITLE: Tullio API: @tullio Macro
DESCRIPTION: Provides a detailed reference for the @tullio macro, outlining its syntax, parameters, and common usage patterns for defining tensor operations. Includes explanations for index notation, reduction operations, and performance tuning flags.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_26

LANGUAGE: APIDOC
CODE:
```
@tullio [output_array[indices]] := [expression] [reduction_operator] [index_definitions] [options]

- **output_array[indices]**: Specifies the output array and its indices. If omitted, a new array is created. Indices can be explicit ranges or inferred.
- **expression**: The mathematical expression defining the tensor operation, using input arrays and indices.
- **reduction_operator**: Optional operator like `sum`, `prod`, `max`, `min` for reduction operations. Defaults to summation.
- **index_definitions**: Explicitly defines the ranges for input or output indices, e.g., `(i in 1:N, j in 1:M)`. Useful when ranges cannot be inferred.
- **options**: Flags to control behavior:
    - `grad=Dual|ForwardDiff|ReverseDiff`: Specifies the automatic differentiation mode.
    - `nograd=symbol1,symbol2,...`: Lists symbols for which gradients should not be computed.
    - `threads=true|false`: Controls multi-threading (defaults to true).
    - `fma=true|false`: Enables fused multiply-add operations.
    - `unsafe=true|false`: Disables safety checks for performance.
    - `parallel=true|false`: Controls parallel execution (often related to threads).
    - `order=...`: Specifies loop ordering for performance.

**Example**: `sum_opp(X, Y=X) = @tullio s := X[i,j] * log(Y[j,i])`
  - `s`: Output scalar variable.
  - `X[i,j] * log(Y[j,i])`: The expression.
  - Implicit summation over `i` and `j`.

**Example with explicit indices and options**: 
`@tullio out[x, y] := @inbounds(begin a,b = off[k]; mat[mod(x+a), mod(y+b)] end) (x in axes(mat,1), y in axes(mat,2)) grad=Dual nograd=off`
  - `out[x, y]`: Output array with explicit indices.
  - `(x in axes(mat,1), y in axes(mat,2))`: Explicit definition of output index ranges.
  - `grad=Dual`, `nograd=off`: Specifies differentiation options.
```

--------------------------------

TITLE: Tullio: Finalizers (<| and |>) and Product Reduction
DESCRIPTION: Demonstrates the use of finalizer operators (<| and |>) for applying functions after reduction and performing product reductions.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_15

LANGUAGE: julia
CODE:
```
using Tullio

# Finalizers <| or |> are applied after sum (the two are equivalent)
@tullio N2[j] := sqrt <| M[i,j]^2     # N2 ≈ map(norm, eachcol(M))
@tullio n3[_] := A[i]^3  |> (_)^(1/3) # n3[1] ≈ norm(A,3), with _ anon. func.

# Reduction over any function (product)
@tullio (*) P[i] := A[i+k]  (k in 0:2) # product
```

--------------------------------

TITLE: Tullio Macro API and Options
DESCRIPTION: Documentation for the `@tullio` macro, detailing its core functionality, integration options with other Julia packages for performance and differentiation, and verbose output controls.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_5

LANGUAGE: APIDOC
CODE:
```
Tullio Macro Usage:

@tullio [options] output_array[indices] := input_expressions

Core Functionality:
- Parses index notation for array operations.
- Supports various reductions (sum, product, min, max).
- Infers index ranges automatically.
- Can perform operations in-place (e.g., `+=`).
- Supports post-reduction function application via pipe operators (`|>`, `<|`).

Integration Options:
- `avx=true/false`: Enables/disables LoopVectorization.@avx optimization (default: true).
- `cuda=true/false`: Enables/disables KernelAbstractions.@kernel for GPU execution (default: true, experimental).
- `grad=true/false`: Enables/disables automatic differentiation (default: true).
- `nograd=A`: Disables gradient calculation for specific arrays (e.g., `nograd=A`).
- `grad=Dual`: Uses ForwardDiff.jl for differentiation (only for '+' reductions).

Gradient Calculation:
- Default: Symbolic differentiation for known functions (DiffRules.jl).
- `grad=Dual`: Uses ForwardDiff.jl for more complex expressions.

Verbose Output:
- `verbose=true`: Prints index ranges, symbolic derivatives, and integration notices.
- `verbose=2`: Prints all verbose information.

Example Usage:
@tullio M[x,y,c] := N[x+i, y+j,c] * K[i,j]     # sum over i,j, and create M
@tullio S[x] = P[x,y] * log(Q[x,y] / R[y])     # sum over y, and write into S
@tullio A[i,j] += B[i,k,l] * C[l,j] * D[k,j]   # sum over k,l, and add to values in A
@tullio (*) Z[j] := X[ind[k],j] * exp(-Y[k])   # product over k
@tullio lse[j] := log <| exp(mat[i,j])       # vec(log.(sum(exp.(mat), dims=1)))

Dependencies:
- LoopVectorization.jl
- KernelAbstractions.jl
- Tracker.jl / ChainRules.jl ecosystem (for autodiff)
- DiffRules.jl
- ForwardDiff.jl (optional, for grad=Dual)
```

--------------------------------

TITLE: Tullio with GPU Acceleration
DESCRIPTION: Shows how Tullio integrates with GPU computing libraries like CUDA and KernelAbstractions. Demonstrates performing matrix multiplication on the GPU and verifying results.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_23

LANGUAGE: Julia
CODE:
```
using CUDA, KernelAbstractions
mul(A, B) = @tullio C[i,k] := A[i,j] * B[j,k]

cu(A * B) ≈ mul(cu(A), cu(B)) # true
```

--------------------------------

TITLE: Tullio: Reductions with Custom Functions (max, min1)
DESCRIPTION: Demonstrates advanced reduction operations using @tullio, including finding the maximum absolute square and custom minimum finding with initial values.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_9

LANGUAGE: julia
CODE:
```
using Tullio, Test

# Reduce using max, over j and δ
@tullio (max) X[i] := abs2(T[j,i,δ])
@test X == dropdims(maximum(abs2, T, dims=(1,3)), dims=(1,3))

# Custom minimum finding function
min1(x,y) = ifelse(first(x) < first(y), x, y);
@tullio (min1) Ts[j+_] := (D[i,j], (i,j))  init=(typemax(Int), (0,0))
```

--------------------------------

TITLE: Batched Matrix Multiplication with Tullio
DESCRIPTION: Demonstrates batched matrix multiplication using Tullio's @tullio macro, comparing its performance and correctness against NNlib.batched_mul. Highlights the need for dimension permutation for the second matrix.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_18

LANGUAGE: Julia
CODE:
```
bmm_rev(A, B) = @tullio C[i,k,b] := A[i,j,b] * B[b,k,j]  # (sum over j)

A = randn(20,30,500); B = randn(500,40,30);
bmm_rev(A, B) ≈ NNlib.batched_mul(A, permutedims(B, (3,2,1)))  # true

@btime bmm_rev($A, $B);
@btime NNlib.batched_mul($A, permutedims($B, (3,2,1)));
```

--------------------------------

TITLE: Tullio: Applying Vector of Functions and Autodiff
DESCRIPTION: Shows how to apply a vector of functions to elements of a matrix using @tullio and demonstrates gradient calculation with Zygote.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_29

LANGUAGE: Julia
CODE:
```
fs = [sin, cos, tan]
xs = randn(3,100)
@tullio ys[r,c] := (fs[r])(xs[r,c])

using Zygote, ForwardDiff
rowmap(fs, xs) = @tullio ys[r,c] := (fs[r])(xs[r,c]) grad=Dual nograd=fs
Zygote.gradient(sum∘rowmap, fs, ones(3,2))
[f'(1) for f in fs] # agrees
```

--------------------------------

TITLE: Tullio: Indexing by Values and Padding
DESCRIPTION: Shows advanced indexing techniques within @tullio, including indexing by values from another array and using padding for out-of-bounds access.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_13

LANGUAGE: julia
CODE:
```
using Tullio

# Index by the values in K
@tullio D[i,j] := A[2K[j]+i] ÷ K[j] # extrema(K)==(-1,2) implies i ∈ 3:17

# Wrapped & padded access
@tullio M[i,j] := A[mod(i+j, axes(A,1))]  (j in 1:15, i in 1:15)   # wraps around
@tullio M[i,j] := A[clamp(i+j)]  (j in 1:15, i in 1:15) # repeats "100"
@tullio M[i+_,j] := A[pad(i+j, 3)]  (j in 1:15)         # fills with zeros
```

--------------------------------

TITLE: Tullio: In-place Updates (Broadcasting Assignment)
DESCRIPTION: Shows how to perform in-place updates on an existing matrix using the @tullio macro, similar to broadcasting assignment.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_10

LANGUAGE: julia
CODE:
```
using Tullio, Test

# Write into existing matrix, M .= 2 .* S
dbl!(M, S) = @tullio M[r,c] = 2 * S[1,c]

# Example usage:
M = zeros(3, 7)
S = rand(1, 7)
dbl!(M, S)
@test all(M[r,c] == 2*S[1,c] for r in 1:3, c in 1:7)
```

--------------------------------

TITLE: Einsum.jl Expansion to For-Loops
DESCRIPTION: Illustrates the low-level, explicit for-loop expansion of the Einsum.jl `@einsum` macro for matrix multiplication. This shows the fundamental operations involved in computing the tensor contraction.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_32

LANGUAGE: julia
CODE:
```
T = promote_type(eltype(A), eltype(B))
C = Array{T}(undef, size(A,1), size(B,2))
@inbounds for j in 1:size(B,2)
    for i in 1:size(A,1)
        acc = zero(T)
        for k in 1:size(A,2)
            acc += A[i,k] * B[k,j]
        end
        C[i,j] = acc
    end
end
```

--------------------------------

TITLE: Tullio: Concatenation and Permutation
DESCRIPTION: Illustrates how Tullio handles operations involving concatenation of arrays and permutations, demonstrated with three nested loops.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_8

LANGUAGE: julia
CODE:
```
using Tullio, Test

R = [rand(Int8, 3, 4) for δ in 1:5]

# Three nested loops -- concatenation
@tullio T[j,i,δ] := R[δ][i,j] + 10im
@test T == permutedims(cat(R...; dims=3), (2,1,3)) .+ 10im
```

--------------------------------

TITLE: Gradients with Tullio and Tracker/Zygote
DESCRIPTION: Illustrates how to compute gradients for operations defined with Tullio using automatic differentiation libraries like Tracker or Zygote. Shows gradient calculation for matrix multiplication and a reduction.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_24

LANGUAGE: Julia
CODE:
```
using Tullio
mul(A, B) = @tullio C[i,k] := A[i,j] * B[j,k]

A = rand(3,40); B = rand(40,500);
A * B ≈ mul(A, B) # true

using Tracker # or Zygote
ΔA = Tracker.gradient((A,B) -> sum(mul(A, B)), A, B)[1]
ΔA ≈ ones(3,500) * B' # true

cu(ΔA) ≈ Tracker.gradient((A,B) -> sum(mul(A, B)), cu(A), cu(B))[1] # true

# Reduction over min/max:
Tracker.gradient(x -> (@tullio (max) res := x[i]^3), [1,2,3,-2,-1,3])[1]
```

--------------------------------

TITLE: Tullio: Dynamic Array Creation and Named Dimensions
DESCRIPTION: Illustrates how functions creating arrays are evaluated once within @tullio and how to use named dimensions with packages like NamedDims and AxisKeys.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_17

LANGUAGE: julia
CODE:
```
using Tullio, NamedDims, AxisKeys

# Functions which create arrays are evaluated once
@tullio R[i,j] := abs.((rand(Int8, 5)[i], rand(Int8, 5)[j]))

# Dimension names, plus pretty printing
@tullio M[row=i, col=j, z=k] := A[i+j-1]  (j in 1:15, k in 1:2)
@tullio S[i] := M[col=j-i, z=k, row=i+1] # sum over j,k
```

--------------------------------

TITLE: Tullio.jl Verbose Output
DESCRIPTION: Explains how to enable verbose output in Tullio.jl to inspect the generated Julia code for both forward and backward passes. This is useful for understanding the expansion and optimization process.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_40

LANGUAGE: julia
CODE:
```
@tullio verbose=2
```

--------------------------------

TITLE: Tullio: In-place Addition with Multiple Reductions
DESCRIPTION: Demonstrates an in-place addition operation (`+=`) on array `A`, summing over indices `k` and `l` involving multiple terms. This is useful for accumulating results.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_2

LANGUAGE: julia
CODE:
```
@tullio A[i,j] += B[i,k,l] * C[l,j] * D[k,j]
```

--------------------------------

TITLE: Tullio for Complex Matrix Expressions
DESCRIPTION: Illustrates how Tullio can express more complex matrix operations, such as those involving subtractions and transposes, and compares its performance to a more optimized manual approach.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_20

LANGUAGE: Julia
CODE:
```
M, Σ = randn(100,100), randn(100,100);
@tullio R4[i, j] := (M[μ, i] - M[μ,j])' * Σ[μ,ν] * (M[ν, i] - M[ν, j]);

begin
  S = M' * Σ * M  # two N^3 operations, instead of one N^4
  @tullio R3[i,j] := S[i,i] + S[j,j] - S[i,j] - S[j,i]
end;
R3 ≈ R4
```

--------------------------------

TITLE: Tullio @tullio Macro Syntax and Options
DESCRIPTION: Explains advanced usage of the @tullio macro, including explicit index range specification, handling of `nograd` and `grad` options, and how assignments affect summation behavior. Demonstrates explicit index definition for output arrays.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_25

LANGUAGE: Julia
CODE:
```
@tullio out[x, y] := @inbounds(begin  # sum over k
        a,b = off[k]
        mat[mod(x+a), mod(y+b)]
    end) (x in axes(mat,1), y in axes(mat,2)) grad=Dual nograd=off
```

--------------------------------

TITLE: Tullio.jl Autodiff Integration (Eval and @adjoint)
DESCRIPTION: Shows how Tullio.jl integrates with automatic differentiation libraries like Zygote. The `Eval` struct and the `@adjoint` macro define the forward and backward pass hooks for gradient computation.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_36

LANGUAGE: julia
CODE:
```
@adjoint function (e::Eval)(AB...)
    C = e.fwd(AB...)
    C, ΔC -> e.rev(ΔC, C, AB...)
end
```

--------------------------------

TITLE: Tullio for Convolution Operations
DESCRIPTION: Demonstrates Tullio's ability to express convolution-like operations using @tullio, including handling padding and strides. Compares performance against Flux.jl's Conv and DSP.jl's conv.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_22

LANGUAGE: Julia
CODE:
```
conv1(x,k) = @tullio y[i+_, j+_] := x[i+a, j+b] * k[a,b]
conv2(x,k) = @tullio y[i+_, j+_] := x[2i-a, 2j-b] * k[a,b]
conv3(x,k) = @tullio y[i+_, j+_] := x[pad(i-a,3), pad(j-b,3)] * k[a,b]

x100 = rand(100,100); k7 = randn(7,7);
@btime conv1($x100, $k7);
@btime conv2($x100, $k7);
@btime conv3($x100, $k7);

using Flux
x104 = reshape(x100,(100,100,1,1)); k74 = reshape(k7,(7,7,1,1)); 
conv1(x100, k7) ≈ @btime CrossCor($k74, false)($x104)
conv2(x100, k7) ≈ @btime Conv($k74, false, stride=2)($x104)
conv3(x100, k7) ≈ @btime Conv($k74, false, pad=3)($x104)

using DSP
@btime DSP.conv($x100, $k7);
```

--------------------------------

TITLE: Broadcast Reductions with Tullio
DESCRIPTION: Shows Tullio's efficiency in broadcast reductions, avoiding large allocations by integrating operations like log directly into the tensor computation. Compares performance and allocations against standard Julia broadcasting.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_21

LANGUAGE: Julia
CODE:
```
sum_opp(X, Y=X) = @tullio s := X[i,j] * log(Y[j,i])
sum_part(X, Y=X) = @tullio S[i] := X[i,j] * log(Y[j,i])

X = rand(1000,1000);
@btime sum_opp($X)
@btime sum($X .* log.(transpose($X)))

@btime sum_part($X)'
@btime sum($X .* log.(transpose($X)), dims=2)
```

--------------------------------

TITLE: Tullio: Post-reduction Function Application
DESCRIPTION: Shows applying a function (`exp`) after a reduction (`sum`) using the pipe operator (`|>`). This allows for operations on the reduced result, like computing the log-sum-exp.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_4

LANGUAGE: julia
CODE:
```
@tullio lse[j] := log <| exp(mat[i,j])
```

--------------------------------

TITLE: Chained Matrix Multiplication Performance
DESCRIPTION: Compares the performance of standard chained matrix multiplication with Tullio's @tullio for expressing the same operation. Shows that Tullio can be significantly slower for naive chained multiplication due to suboptimal algorithm selection.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_19

LANGUAGE: Julia
CODE:
```
M1, M2, M3 = randn(30,30), randn(30,30), randn(30,30);
@btime $M1 * $M2 * $M3;
@btime @tullio M4[i,l] := $M1[i,j] * $M2[j,k] * $M3[k,l];
```

--------------------------------

TITLE: Tullio: Convolution with Cyclic Indices
DESCRIPTION: Demonstrates using the @tullio macro for a convolution operation with cyclic indices, utilizing `mod` for index wrapping and manual `@inbounds`.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_27

LANGUAGE: Julia
CODE:
```
mat = zeros(10,10,1); mat[2,2] = 101; mat[10,10] = 1;
@tullio kern[i,j] := 1/(1+i^2+j^2)  (i in -3:3, j in -3:3)

@tullio out[x,y,c] := begin
    xi = mod(x+i, axes(mat,1)) # xi = ... means that it won't be summed,
    # yj = mod(y+j, axes(mat,2))
    @inbounds trunc(Int, mat[xi, mod(y+j), c] * kern[i,j]) # and disables automatic @inbounds,
end (x in 1:10, y in 1:10) # and prevents range of x from being inferred.
```

--------------------------------

TITLE: Tullio: Convolution with Offset Arrays
DESCRIPTION: Demonstrates convolution of a filter (defined with OffsetArrays) with an array using the @tullio macro.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_12

LANGUAGE: julia
CODE:
```
using Tullio, OffsetArrays

# Convolve a filter
K = OffsetArray([1,-1,2,-1,1], -2:2)
@tullio C[i] := A[i+j] * K[j]    # j ∈ -2:2 implies i ∈ 3:19
```

--------------------------------

TITLE: Tullio.jl Matrix Multiplication with tanh
DESCRIPTION: Shows a Tullio.jl macro usage for matrix multiplication combined with a post-operation (tanh). This demonstrates how Tullio handles applying functions to the results of contractions.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_33

LANGUAGE: julia
CODE:
```
@tullio C[i,j] := tanh <| A[i,k] * B[k,j]
```

--------------------------------

TITLE: Tullio: Accessing Struct Fields and Arrays
DESCRIPTION: Shows how to access fields of structs and elements of arrays within the @tullio macro for complex data structures.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_16

LANGUAGE: julia
CODE:
```
using Tullio

# Access to fields & arrays
N = [(a=i, b=i^2, c=fill(i^3,3)) for i in 1:10]
@tullio T[i,j] := (N[i].a // 1, N[i].c[j])
```

--------------------------------

TITLE: Tullio.jl Gradient Calculation with Dual Numbers
DESCRIPTION: Shows an alternative gradient calculation method in Tullio.jl using ForwardDiff.jl's `Dual` numbers. This approach is used when finalizers like `tanh` are not directly differentiable in terms of the intermediate sum, and it computes gradients by perturbing inputs.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_39

LANGUAGE: julia
CODE:
```
function ∇act!(::Type, ΔC, ΔA, ΔB, C, A, B, ax_i, ax_j, ax_k, keep)
    eps1 = ForwardDiff.Dual(0, (1,0))
    eps2 = ForwardDiff.Dual(0, (0,1))
    for k in ax_k, i in ax_i, j in ax_j
        res = (A[i,k] + eps1) * (B[k,j] + eps2)
        ΔA[i,k] += ForwardDiff.partials(res, 1) * ΔC[i,j]
        ΔB[k,j] += ForwardDiff.partials(res, 2) * ΔC[i,j]
    end
end
```

--------------------------------

TITLE: Tullio: Assign Result of Summation
DESCRIPTION: Shows summing over index `y` and writing the result into array `S`. This illustrates a common pattern of reduction and assignment to an existing array.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_1

LANGUAGE: julia
CODE:
```
@tullio S[x] = P[x,y] * log(Q[x,y] / R[y])
```

--------------------------------

TITLE: Tullio.jl Backward Pass Expansion (∇act!)
DESCRIPTION: Details the expanded Julia function (`∇act!`) generated by Tullio.jl for computing gradients. This function calculates the partial derivatives with respect to the input arrays based on the forward pass results and the incoming gradient.

SOURCE: https://github.com/mcabbott/tullio.jl/blob/master/README.md#_snippet_37

LANGUAGE: julia
CODE:
```
function ∇act!(::Type, ΔC, ΔA, ΔB, C, A, B, ax_i, ax_j, ax_k, keep)
    for k in ax_k, i in ax_i, j in ax_j
        ex = ΔC[i,j] * (1-C[i,j])^2
        ΔA[i,k] += ex * B[k,j]
        ΔB[k,j] += A[i,k] * ex
    end
end
```